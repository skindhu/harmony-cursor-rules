"""
ArkTSè§„åˆ™æå–å™¨æ¨¡å—
ä»åä¸ºå¼€å‘è€…æ–‡æ¡£ä¸­æå–arkts-no-*è§„åˆ™å¹¶æ ¼å¼åŒ–ä¸ºcursor rules
"""

import re
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup
from crawler import WebCrawler
from config import ConfigManager
from gemini_api import GeminiAPI


class ArkTSRulesExtractor:
    """ArkTSè§„åˆ™æå–å™¨"""

    def __init__(self, web_crawler: WebCrawler, gemini_api: GeminiAPI, output_dir: Path = None):
        """
        åˆå§‹åŒ–è§„åˆ™æå–å™¨

        Args:
            web_crawler: ç½‘é¡µçˆ¬è™«å®ä¾‹
            gemini_api: Gemini APIå®ä¾‹
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneæ—¶ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        self.web_crawler = web_crawler
        self.gemini_api = gemini_api

        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            self.output_dir = Path("harmony_cursor_rules/final_cursor_rules")
        else:
            self.output_dir = output_dir / "final_cursor_rules"

        self.output_dir.mkdir(parents=True, exist_ok=True)

    async def extract_arkts_rules_from_url(
        self,
        url: str = "https://developer.huawei.com/consumer/en/doc/harmonyos-guides-V14/typescript-to-arkts-migration-guide-V14"
    ) -> Dict[str, Any]:
        """
        ä»æŒ‡å®šURLæå–ArkTSè§„åˆ™

        Args:
            url: ç›®æ ‡URL

        Returns:
            Dict: æå–ç»“æœ
        """
        print("ğŸš€ å¼€å§‹æå–ArkTS Lintè§„åˆ™")
        print("=" * 50)
        print(f"ğŸ“„ ç›®æ ‡é¡µé¢: {url}")

        # çˆ¬å–é¡µé¢
        crawl_result = await self.web_crawler.crawl_single_page(
            url=url,
            module_name="arkts_migration_guide",
            use_spa_mode=True,
            extract_best_practices=False
        )

        if not crawl_result.get('success', False):
            error_msg = crawl_result.get('error', 'æœªçŸ¥é”™è¯¯')
            print(f"âŒ é¡µé¢çˆ¬å–å¤±è´¥: {error_msg}")
            return {
                "success": False,
                "error": f"é¡µé¢çˆ¬å–å¤±è´¥: {error_msg}",
                "rules_count": 0
            }

        print("âœ… é¡µé¢çˆ¬å–æˆåŠŸ")

        # ä»çˆ¬å–ç»“æœä¸­è·å–HTMLå†…å®¹
        html_content = self._get_html_content_from_crawl_result(crawl_result)

        if not html_content:
            print("âŒ æ— æ³•è·å–HTMLå†…å®¹")
            return {
                "success": False,
                "error": "æ— æ³•è·å–HTMLå†…å®¹",
                "rules_count": 0
            }

        # æå–è§„åˆ™ - ä½¿ç”¨AIæ™ºèƒ½æå–
        rules_result = self._extract_arkts_rules_with_ai(html_content)

        if not rules_result.get("success", False):
            error_msg = rules_result.get("error", "AIæå–å¤±è´¥")
            print(f"âš ï¸ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "rules_count": 0
            }

        rules = rules_result.get("rules", [])

        if not rules:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•arkts-no-*è§„åˆ™")
            return {
                "success": False,
                "error": "æœªæ‰¾åˆ°ä»»ä½•arkts-no-*è§„åˆ™",
                "rules_count": 0
            }

        print(f"ğŸ“‹ æ‰¾åˆ° {len(rules)} ä¸ªArkTSè§„åˆ™")

        # ç”Ÿæˆcursor rulesæ–‡ä»¶
        markdown_content = self._generate_cursor_rules_markdown(rules)

        # ä¿å­˜æ–‡ä»¶
        output_file = self.output_dir / "arkts-lint-rules.md"
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)

            print(f"âœ… è§„åˆ™æ–‡ä»¶å·²ä¿å­˜: {output_file}")
            return {
                "success": True,
                "output_file": str(output_file),
                "rules_count": len(rules),
                "rules": rules
            }

        except Exception as e:
            print(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}",
                "rules_count": len(rules)
            }

    def _get_html_content_from_crawl_result(self, crawl_result: Dict[str, Any]) -> Optional[str]:
        """
        ä»çˆ¬å–ç»“æœä¸­è·å–HTMLå†…å®¹

        Args:
            crawl_result: çˆ¬å–ç»“æœ

        Returns:
            Optional[str]: HTMLå†…å®¹
        """
        # ä¼˜å…ˆä»çˆ¬å–ç»“æœä¸­ç›´æ¥è·å–HTMLå†…å®¹
        html_content = crawl_result.get('html_content')
        if html_content:
            return html_content


        return None

    def _extract_arkts_rules_with_ai(self, html_content: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨AIä»HTMLå†…å®¹ä¸­æå–arkts-no-*è§„åˆ™

        Args:
            html_content: HTMLå†…å®¹

        Returns:
            Dict: æå–ç»“æœï¼ŒåŒ…å«successå’Œruleså­—æ®µ
        """
        try:
            # ä½¿ç”¨BeautifulSoupæ¸…ç†HTMLï¼Œæå–çº¯æ–‡æœ¬
            soup = BeautifulSoup(html_content, 'html.parser')

            # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
            for script in soup(["script", "style"]):
                script.decompose()

            # è·å–çº¯æ–‡æœ¬å†…å®¹
            text_content = soup.get_text()

            print(f"ğŸ“ å‡†å¤‡AIæå–ï¼Œæ–‡æœ¬é•¿åº¦: {len(text_content)} å­—ç¬¦")

            # æ„å»ºAIæç¤ºè¯
            extraction_prompt = self._build_arkts_extraction_prompt(text_content)

            # ç›´æ¥ä½¿ç”¨Gemini APIæå–è§„åˆ™
            ai_response = self.gemini_api.generate_text(extraction_prompt)

            if not ai_response:
                return {
                    "success": False,
                    "error": "AIæœªè¿”å›ä»»ä½•å†…å®¹"
                }

            # è§£æAIè¿”å›çš„è§„åˆ™
            rules = self._parse_ai_response_text(ai_response)

            if not rules:
                return {
                    "success": False,
                    "error": "AIæœªèƒ½æå–åˆ°æœ‰æ•ˆçš„arkts-no-*è§„åˆ™"
                }

            print(f"ğŸ¤– AIæˆåŠŸæå– {len(rules)} ä¸ªè§„åˆ™")

            return {
                "success": True,
                "rules": rules,
                "rules_count": len(rules)
            }

        except Exception as e:
            print(f"âŒ AIæå–è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "success": False,
                "error": f"AIæå–è¿‡ç¨‹é”™è¯¯: {str(e)}"
            }

    def _build_arkts_extraction_prompt(self, content: str) -> str:
        """
        æ„å»ºArkTSè§„åˆ™æå–çš„AIæç¤ºè¯

        Args:
            content: é¡µé¢æ–‡æœ¬å†…å®¹

        Returns:
            str: AIæç¤ºè¯
        """
        prompt = f"""
è¯·ä»ä»¥ä¸‹åä¸ºHarmonyOS ArkTSè¿ç§»æŒ‡å—å†…å®¹ä¸­ï¼Œæå–æ‰€æœ‰çš„ArkTS Lintè§„åˆ™ï¼ˆä»¥"arkts-no-"å¼€å¤´çš„è§„åˆ™ï¼‰ã€‚

ä»»åŠ¡è¦æ±‚ï¼š
1. æ‰¾å‡ºæ‰€æœ‰ä»¥"arkts-no-"å¼€å¤´çš„è§„åˆ™åç§°
2. ä¸ºæ¯ä¸ªè§„åˆ™æå–å¯¹åº”çš„æè¿°ä¿¡æ¯
3. è§„åˆ™åç§°ç»Ÿä¸€è½¬æ¢ä¸ºå°å†™
4. æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›

è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹å†…å®¹å¹¶æå–è§„åˆ™ï¼š

{content}

è¯·ä»¥ä»¥ä¸‹JSONæ ¼å¼è¿”å›æå–çš„è§„åˆ™ï¼š
```json
[
  {{
    "name": "arkts-no-xxx",
    "severity": "error",
    "description": "è§„åˆ™çš„è¯¦ç»†æè¿°",
    "suggestion": "å»ºè®®çš„æ›¿ä»£å®è·µæ–¹å¼"
  }},
  {{
    "name": "arkts-no-yyy",
    "severity": "error",
    "description": "è§„åˆ™çš„è¯¦ç»†æè¿°",
    "suggestion": "å»ºè®®çš„æ›¿ä»£å®è·µæ–¹å¼"
  }}
]
```

æ³¨æ„äº‹é¡¹ï¼š
- åªæå–ä»¥"arkts-no-"å¼€å¤´çš„è§„åˆ™
- ç¡®ä¿æ¯ä¸ªè§„åˆ™éƒ½æœ‰æ¸…æ™°çš„æè¿°å’Œå»ºè®®
- è§„åˆ™åç§°å¿…é¡»å®Œæ•´ä¸”å‡†ç¡®
- æè¿°è¦ç®€æ´æ˜äº†ï¼Œè¯´æ˜è¯¥è§„åˆ™çš„ä½œç”¨
- suggestionå­—æ®µè¦æä¾›å…·ä½“çš„æ›¿ä»£æ–¹æ¡ˆæˆ–æœ€ä½³å®è·µ
- å¦‚æœåŒä¸€ä¸ªè§„åˆ™å‡ºç°å¤šæ¬¡ï¼Œåªä¿ç•™ä¸€æ¬¡
- ä¸¥é‡ç¨‹åº¦ç»Ÿä¸€è®¾ç½®ä¸º"error"
"""
        return prompt

    def _parse_ai_response_text(self, ai_response: str) -> List[Dict[str, str]]:
        """
        è§£æAIè¿”å›çš„æ–‡æœ¬ï¼Œæå–ArkTSè§„åˆ™

        Args:
            ai_response: AIè¿”å›çš„åŸå§‹æ–‡æœ¬

        Returns:
            List[Dict]: è§£æåçš„è§„åˆ™åˆ—è¡¨
        """
        rules = []

        try:
            # é¦–å…ˆå°è¯•ä»JSONæ ¼å¼ä¸­æå–
            rules.extend(self._extract_rules_from_json_text(ai_response))

            # å¦‚æœæ²¡æœ‰JSONï¼Œå°è¯•ä»çº¯æ–‡æœ¬ä¸­æå–
            if not rules:
                rules.extend(self._extract_rules_from_plain_text(ai_response))

            # å»é‡å’Œæ’åº
            unique_rules = self._deduplicate_rules(rules)

            return unique_rules

        except Exception as e:
            print(f"âš ï¸ è§£æAIç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []

    def _extract_rules_from_json_text(self, text: str) -> List[Dict[str, str]]:
        """
        ä»æ–‡æœ¬ä¸­æå–JSONæ ¼å¼çš„è§„åˆ™

        Args:
            text: åŒ…å«JSONçš„æ–‡æœ¬

        Returns:
            List[Dict]: è§„åˆ™åˆ—è¡¨
        """
        rules = []

        try:
            # æŸ¥æ‰¾JSONä»£ç å—
            json_pattern = r'```json\s*(.*?)\s*```'
            json_matches = re.findall(json_pattern, text, re.DOTALL)

            for json_text in json_matches:
                try:
                    parsed_rules = json.loads(json_text)
                    if isinstance(parsed_rules, list):
                        for rule in parsed_rules:
                            if self._is_valid_arkts_rule(rule):
                                rules.append(rule)
                except json.JSONDecodeError:
                    continue

            # å¦‚æœæ²¡æ‰¾åˆ°ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬
            if not rules:
                try:
                    parsed_rules = json.loads(text)
                    if isinstance(parsed_rules, list):
                        for rule in parsed_rules:
                            if self._is_valid_arkts_rule(rule):
                                rules.append(rule)
                except json.JSONDecodeError:
                    pass

        except Exception as e:
            print(f"âš ï¸ JSONè§£æé”™è¯¯: {e}")

        return rules

    def _extract_rules_from_plain_text(self, text: str) -> List[Dict[str, str]]:
        """
        ä»çº¯æ–‡æœ¬ä¸­æå–è§„åˆ™ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰

        Args:
            text: çº¯æ–‡æœ¬å†…å®¹

        Returns:
            List[Dict]: è§„åˆ™åˆ—è¡¨
        """
        rules = []

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾arkts-no-*è§„åˆ™
        pattern = r'(arkts-no-[\w-]+)[:\s]*([^\n\r]+)'
        matches = re.findall(pattern, text, re.IGNORECASE)

        for rule_name, description in matches:
            rule_name = rule_name.lower()
            description = description.strip()

            if len(description) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æè¿°
                # ä»æè¿°ä¸­å°è¯•æå–å»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
                suggestion = "Use ArkTS-compatible alternatives as specified in the documentation."
                if "Use " in description or "use " in description:
                    # å¦‚æœæè¿°ä¸­åŒ…å«å»ºè®®ï¼Œæå–ååŠéƒ¨åˆ†ä½œä¸ºsuggestion
                    parts = description.split("Use ", 1)
                    if len(parts) > 1:
                        suggestion = "Use " + parts[1]
                        description = parts[0].rstrip(" .;,")

                rules.append({
                    "name": rule_name,
                    "severity": "error",
                    "description": description,
                    "suggestion": suggestion
                })

        return rules

    def _is_valid_arkts_rule(self, rule: Dict[str, Any]) -> bool:
        """
        éªŒè¯è§„åˆ™æ˜¯å¦æœ‰æ•ˆ

        Args:
            rule: è§„åˆ™å­—å…¸

        Returns:
            bool: æ˜¯å¦æœ‰æ•ˆ
        """
        if not isinstance(rule, dict):
            return False

        name = rule.get("name", "")
        description = rule.get("description", "")
        suggestion = rule.get("suggestion", "")

        return (
            isinstance(name, str) and
            name.lower().startswith("arkts-no-") and
            isinstance(description, str) and
            len(description.strip()) > 5 and
            isinstance(suggestion, str) and
            len(suggestion.strip()) > 5
        )

    def _deduplicate_rules(self, rules: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        å»é‡è§„åˆ™

        Args:
            rules: è§„åˆ™åˆ—è¡¨

        Returns:
            List[Dict]: å»é‡åçš„è§„åˆ™åˆ—è¡¨
        """
        seen_names = set()
        unique_rules = []

        for rule in rules:
            name = rule["name"]
            if name not in seen_names:
                seen_names.add(name)
                unique_rules.append(rule)

        # æŒ‰åç§°æ’åº
        unique_rules.sort(key=lambda x: x["name"])

        return unique_rules

    def _generate_cursor_rules_markdown(self, rules: List[Dict[str, str]]) -> str:
        """
        ç”Ÿæˆcursor rulesæ ¼å¼çš„markdownå†…å®¹

        Args:
            rules: è§„åˆ™åˆ—è¡¨

        Returns:
            str: markdownå†…å®¹
        """
        # å°†è§„åˆ™è½¬æ¢ä¸ºJSONæ ¼å¼
        rules_json = json.dumps(rules, indent=2, ensure_ascii=False)

        markdown_content = f"""# ArkTS Lint Rules - Cursor Rules

## æ¦‚è¿°
ArkTSï¼ˆTypeScriptçš„å­é›†ï¼‰çš„Lintè§„åˆ™ï¼Œç”¨äºç¡®ä¿ä»£ç ç¬¦åˆHarmonyOSå¼€å‘è§„èŒƒã€‚

## è§„åˆ™ç»Ÿè®¡
- æ€»è§„åˆ™æ•°é‡: {len(rules)}
- ä¸¥é‡ç¨‹åº¦: error
- é€‚ç”¨èŒƒå›´: ArkTS/TypeScriptä»£ç 

## è§„åˆ™åˆ—è¡¨

### JSONæ ¼å¼
```json
{rules_json}
```

## ä½¿ç”¨è¯´æ˜

### åœ¨Cursorä¸­ä½¿ç”¨
1. å°†æ­¤æ–‡ä»¶ä¿å­˜ä¸º `.cursorrules` æ–‡ä»¶
2. é…ç½®TypeScript/ArkTSé¡¹ç›®çš„ESLintè§„åˆ™
3. ç¡®ä¿IDEèƒ½å¤Ÿè¯†åˆ«è¿™äº›è§„åˆ™

### è§„åˆ™åº”ç”¨
è¿™äº›è§„åˆ™ä¸»è¦ç”¨äºï¼š
- TypeScriptåˆ°ArkTSçš„è¿ç§»
- HarmonyOSåº”ç”¨å¼€å‘
- ç¡®ä¿ä»£ç ç¬¦åˆArkTSè§„èŒƒ

## å‚è€ƒèµ„æº
- [HarmonyOS ArkTSå¼€å‘æŒ‡å—](https://developer.huawei.com/consumer/en/doc/harmonyos-guides-V14/typescript-to-arkts-migration-guide-V14)
- ç”Ÿæˆæ—¶é—´: {self._get_current_time()}

---
*æ­¤æ–‡ä»¶ç”±ArkTSè§„åˆ™æå–å™¨è‡ªåŠ¨ç”Ÿæˆ*
"""

        return markdown_content

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def get_extractor_stats(self) -> Dict[str, Any]:
        """
        è·å–æå–å™¨ç»Ÿè®¡ä¿¡æ¯

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            'web_crawler_ready': self.web_crawler is not None,
            'ai_processor_ready': self.gemini_api is not None,
            'output_directory': str(self.output_dir),
            'output_directory_exists': self.output_dir.exists(),
            'extraction_method': 'AI-powered (Gemini)'
        }
